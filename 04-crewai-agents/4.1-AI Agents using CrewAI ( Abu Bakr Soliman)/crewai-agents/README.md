# CrewAI Procurement Agents ğŸ¤–

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![CrewAI](https://img.shields.io/badge/CrewAI-0.1.30+-orange.svg)](https://github.com/joaomdmoura/crewAI)
[![LangChain](https://img.shields.io/badge/LangChain-0.0.335+-green.svg)](https://github.com/langchain-ai/langchain)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Contributions](https://img.shields.io/badge/Contributions-Welcome-brightgreen.svg)](https://github.com/Fawzy-AI-Explorer/NLP-Tea/issues)
[![Stars](https://img.shields.io/github/stars/Fawzy-AI-Explorer/NLP-Tea?style=social)](https://github.com/Fawzy-AI-Explorer/NLP-Tea/stargazers)

A modular AI agent system built with CrewAI for product research, procurement, and analysis in e-commerce environments.

## Project Overview ğŸ”

This project implements a multi-agent system using CrewAI to automate the process of researching products, searching e-commerce websites, scraping relevant information, and generating procurement reports. The system is designed to help businesses make informed purchasing decisions by collecting and analyzing product data from various online sources.

## Features âœ¨

- **Search Query Generation**: AI agent that generates optimized search queries for product research
- **Search Engine Processing**: Agent that queries e-commerce sites and extracts relevant results
- **Web Scraping**: Agent that collects detailed product information from search results
- **Procurement Reports**: Agent that analyzes scraped data and creates comprehensive procurement reports

## Installation ğŸ’»

1. Clone the repository:
   ```bash
   git clone https://github.com/Fawzy-AI-Explorer/NLP-Tea.git
   cd NLP-Tea/04-crewai-agents/4.1-AI\ Agents\ using\ CrewAI\ \(\ Abu\ Bakr\ Soliman\)/crewai-agents
   ```

2. Create and activate a virtual environment (recommended):
   ```bash
   # For Windows
   python -m venv venv
   source venv\Scripts\activate
   ```

3. Install required packages:
   ```bash
   pip install -r requirements.txt
   ```

4. Set up your environment variables:
   ```bash
   # Create a .env file with your API keys
   OPENAI_API_KEY=your_openai_api_key 
   AGENTOPS_API_KEY=your_agentops_api_key 
   # Add other API keys as needed
   ```

## Project Structure ğŸ“‚

```
crewai-agents/
â”‚
â”‚
â”œâ”€â”€ crewai_agents/                   - Core module containing all agent definitions
â”‚   â”œâ”€â”€ __init__.py                  - Package initialization
â”‚   â”œâ”€â”€ config.py                    - Configuration settings
â”‚   â”œâ”€â”€ utilis.py                    - Utility functions
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/                      - Individual agent implementations
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ a1_search_queries_agent.py   - Search query generation agent
â”‚   â”‚   â”œâ”€â”€ a2_search_engine_agent.py    - Search engine processing agent
â”‚   â”‚   â”œâ”€â”€ a3_scraping_agent.py         - Web scraping agent
â”‚   â”‚   â””â”€â”€ a4_procurement_report.py     - Procurement report generation agent
â”‚   â”‚
â”‚   â”‚
â”‚   â””â”€â”€ tasks/                       - Task definitions for each agent
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ t1_search_queries_task.py    - Search query generation task
â”‚       â”œâ”€â”€ t2_search_engine_task.py     - Search engine task
â”‚       â”œâ”€â”€ t3_scraping_task.py          - Web scraping task
â”‚       â””â”€â”€ t4_procurement_report_task.py - Procurement report generation task
â”‚
â”œâ”€â”€ examples/                        - Example scripts to run individual agents or full workflows
â”‚   â”œâ”€â”€ ex1_run_search_queries_agent.py  - Run search queries agent
â”‚   â”œâ”€â”€ ex2_run_search_engine_agent.py   - Run search engine agent
â”‚   â””â”€â”€ ex3_run_procurement_report_agent.py - Run procurement report agent
|   
â”‚
â”œâ”€â”€ outputs/                         - Output directory for agent results
â”‚   â””â”€â”€ ai-agent-output/             - JSON outputs from agent runs
â”‚       â”œâ”€â”€ step_1_suggested_search_queries.json - Output from search queries agent
â”‚       â”œâ”€â”€ step_2_search_results.json           - Output from search engine agent
â”‚       â”œâ”€â”€ step_3_scraping_results.json         - Output from web scraping agent
â”‚       â””â”€â”€ step_4_procurement_report.html       - Final procurement report output
â”‚
â”œâ”€â”€ tests/                           - Unit and integration tests
â”‚   â””â”€â”€ test.py                      - Test script
â”‚
â”œâ”€â”€ requirements.txt                 - Project dependencies
â””â”€â”€ README.md                        - Project documentation
```

## Output Files ğŸ“

The agents produce the following output files during execution:

```
outputs/
â””â”€â”€ ai-agent-output/
    â”œâ”€â”€ step_1_suggested_search_queries.json - Output from search queries agent
    â”œâ”€â”€ step_2_search_results.json           - Output from search engine agent
    â”œâ”€â”€ step_3_scraping_results.json         - Output from web scraping agent
    â””â”€â”€ step_4_procurement_report.html       - Final procurement report output (HTML format)
```

## Usage ğŸš€

### 1. Generate Search Queries ğŸ”

```python
from examples.ex1_run_search_queries_agent import run_search_queries_agent

results = run_search_queries_agent()
print(results)
```

### 2. Run Search Engine Agent ğŸŒ

```python
from examples.ex2_run_search_engine_agent import run_search_engine_agent

results = run_search_engine_agent()
print(results)
```

### 3. Generate Procurement Report ğŸ“Š

```python
from examples.ex3_run_procurement_report_agent import run_procurement_report_agent

results = run_procurement_report_agent()
print(results)
```

## Complete Workflow ğŸ”„

workflow:
1. Generates optimized search queries for your product requirements
2. Searches e-commerce sites using these queries
3. Scrapes detailed product information from search results
4. Produces a comprehensive procurement report with recommendations

## License ğŸ“œ

## Contributing ğŸ¤

Contributions are welcome! Please feel free to submit a Pull Request.

## Acknowledgments ğŸ™

- Thanks to the [Abu Bakr Soliman](https://www.linkedin.com/in/bakrianoo/) for this [crash course](https://www.youtube.com/watch?v=DDR4A8-MLQs&t=1s)