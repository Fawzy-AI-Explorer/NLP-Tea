{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3316532,"sourceType":"datasetVersion","datasetId":10100}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd \n# preprocessing\nimport re\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nnltk.download('wordnet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:17:58.089901Z","iopub.execute_input":"2025-04-19T17:17:58.090490Z","iopub.status.idle":"2025-04-19T17:18:02.530545Z","shell.execute_reply.started":"2025-04-19T17:17:58.090456Z","shell.execute_reply":"2025-04-19T17:18:02.529578Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":1},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"file_path = r\"/kaggle/input/yelp-dataset/yelp_academic_dataset_tip.json\"\ndf = pd.read_json(file_path, lines=True)\ndf = df[:1000]\n\ntext_column = df['text']\ntext_column.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:18:02.531766Z","iopub.execute_input":"2025-04-19T17:18:02.532185Z","iopub.status.idle":"2025-04-19T17:18:10.677540Z","shell.execute_reply.started":"2025-04-19T17:18:02.532157Z","shell.execute_reply":"2025-04-19T17:18:10.676617Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"0                       Avengers time with the ladies.\n1    They have lots of good deserts and tasty cuban...\n2               It's open even when you think it isn't\n3                            Very decent fried chicken\n4               Appetizers.. platter special for lunch\nName: text, dtype: object"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:18:10.678316Z","iopub.execute_input":"2025-04-19T17:18:10.678558Z","iopub.status.idle":"2025-04-19T17:18:10.684053Z","shell.execute_reply.started":"2025-04-19T17:18:10.678538Z","shell.execute_reply":"2025-04-19T17:18:10.683203Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(1000, 5)"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"def preprocess(text: str) -> list :\n    text = text.lower()\n    text = re.sub(r'[^a-zA-Z\\s]', '', text)       # Remove all non-alphabetic characters\n    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)   # Remove all single characters\n\n    tokens = text.split()\n    tokens = [t for t in tokens if len(t)>3]      # Keep words with length >= 3\n\n    stop_words = set(stopwords.words('english'))\n    lemmatizer = WordNetLemmatizer() \n\n    tokens = [lemmatizer.lemmatize(t) for t in tokens if t not in stop_words]\n    return tokens if tokens else []               # Return an empty list if nothing remains\n\nsentences = [preprocess(t) for t in text_column] # List[List[str]]\nprint(sentences[:3])\nlen(sentences)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:18:10.685927Z","iopub.execute_input":"2025-04-19T17:18:10.686209Z","iopub.status.idle":"2025-04-19T17:18:13.899032Z","shell.execute_reply.started":"2025-04-19T17:18:10.686179Z","shell.execute_reply":"2025-04-19T17:18:13.898150Z"}},"outputs":[{"name":"stdout","text":"[['avenger', 'time', 'lady'], ['lot', 'good', 'desert', 'tasty', 'cuban', 'sandwich'], ['open', 'even', 'think', 'isnt']]\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"1000"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Official FastText","metadata":{}},{"cell_type":"code","source":"from gensim.models import FastText","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:18:13.903216Z","iopub.execute_input":"2025-04-19T17:18:13.903959Z","iopub.status.idle":"2025-04-19T17:18:54.429621Z","shell.execute_reply.started":"2025-04-19T17:18:13.903934Z","shell.execute_reply":"2025-04-19T17:18:54.428969Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Train FastText model\nFastText_model = FastText(\n    sentences=sentences,\n    vector_size=100,\n    window=3,\n    min_count=1,\n    epochs=500\n)\nprint(FastText_model)\n# Save the model\nFastText_model.save(\"fasttext_model.model\")\nprint(\"model saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:18:54.430461Z","iopub.execute_input":"2025-04-19T17:18:54.430938Z","iopub.status.idle":"2025-04-19T17:19:12.717566Z","shell.execute_reply.started":"2025-04-19T17:18:54.430916Z","shell.execute_reply":"2025-04-19T17:19:12.716625Z"}},"outputs":[{"name":"stdout","text":"FastText<vocab=2121, vector_size=100, alpha=0.025>\nmodel saved.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"vocab_size = len(FastText_model.wv)\nembedding_size = FastText_model.vector_size\n\n# Print vocabulary and embedding size\nprint(f\"Vocabulary Size: {vocab_size}\")\nprint(f\"Embedding Size: {embedding_size}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:19:12.719832Z","iopub.execute_input":"2025-04-19T17:19:12.720076Z","iopub.status.idle":"2025-04-19T17:19:12.725155Z","shell.execute_reply.started":"2025-04-19T17:19:12.720058Z","shell.execute_reply":"2025-04-19T17:19:12.724125Z"}},"outputs":[{"name":"stdout","text":"Vocabulary Size: 2121\nEmbedding Size: 100\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"similar_words = FastText_model.wv.most_similar('good', topn=10)\nprint(\"\\nSimilar\")\nprint(similar_words)\nprint(\"-\"*30) \nopposite_words = FastText_model.wv.most_similar(negative= 'good', topn=10)\nprint(\"\\n\", opposite_words)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:19:12.726119Z","iopub.execute_input":"2025-04-19T17:19:12.726446Z","iopub.status.idle":"2025-04-19T17:19:12.750329Z","shell.execute_reply.started":"2025-04-19T17:19:12.726416Z","shell.execute_reply":"2025-04-19T17:19:12.749248Z"}},"outputs":[{"name":"stdout","text":"\nSimilar\n[('goodi', 0.8452088832855225), ('food', 0.5561390519142151), ('deliciously', 0.5237860083580017), ('neighborhood', 0.4961780607700348), ('deliciousness', 0.4901498854160309), ('deliciousthen', 0.4899592697620392), ('ipod', 0.4890640377998352), ('foodgreat', 0.47072115540504456), ('delicious', 0.46029138565063477), ('bollywood', 0.4556906819343567)]\n------------------------------\n\n [('postage', 0.3698478043079376), ('hermitage', 0.3362504243850708), ('cinco', 0.3282019793987274), ('lurk', 0.3278462290763855), ('professionalism', 0.31859180331230164), ('postal', 0.31132882833480835), ('prepaid', 0.30549004673957825), ('trip', 0.30125343799591064), ('trap', 0.2973553240299225), ('ease', 0.2962052822113037)]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# pretrained FastText model","metadata":{}},{"cell_type":"code","source":"# Download Model\nimport urllib.request\nimport gzip\nimport os\nimport shutil","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:19:12.751634Z","iopub.execute_input":"2025-04-19T17:19:12.751965Z","iopub.status.idle":"2025-04-19T17:19:12.756263Z","shell.execute_reply.started":"2025-04-19T17:19:12.751942Z","shell.execute_reply":"2025-04-19T17:19:12.755380Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Download pretrained FastText model\nurl = \"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\"\noutput_gz = \"cc.en.300.bin.gz\"\noutput_bin = \"cc.en.300.bin\"\n\n# Download the .gz file\nprint(\"Downloading pretrained FastText model...\")\nurllib.request.urlretrieve(url, output_gz)\n\n# Unzip the .gz file\nprint(\"Unzipping the model...\")\nwith gzip.open(output_gz, 'rb') as f_in:\n    with open(output_bin, 'wb') as f_out:\n        shutil.copyfileobj(f_in, f_out)\nprint(\"model saved\")\n# Remove the .gz file to save space\nos.remove(output_gz)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:19:12.757106Z","iopub.execute_input":"2025-04-19T17:19:12.757990Z","iopub.status.idle":"2025-04-19T17:20:21.869886Z","shell.execute_reply.started":"2025-04-19T17:19:12.757961Z","shell.execute_reply":"2025-04-19T17:20:21.869086Z"}},"outputs":[{"name":"stdout","text":"Downloading pretrained FastText model...\nUnzipping the model...\nmodel saved\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import fasttext","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:20:21.870774Z","iopub.execute_input":"2025-04-19T17:20:21.871056Z","iopub.status.idle":"2025-04-19T17:20:21.896035Z","shell.execute_reply.started":"2025-04-19T17:20:21.871036Z","shell.execute_reply":"2025-04-19T17:20:21.895138Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"print(\"Loading the model...\")\npretrained = fasttext.load_model(output_bin)\nprint(pretrained)\nvocab_size = len(pretrained.words)\nembedding_size = pretrained.get_dimension()\nprint(f\"Vocabulary Size: {vocab_size}\")\nprint(f\"Embedding Size: {embedding_size}\")\n# --------------------\nsimilar_words = pretrained.get_nearest_neighbors(\"good\", k=10)\nprint(\"similar words\",similar_words)\nopposite_words = pretrained.get_nearest_neighbors(negative=[\"learning\"], k=10)\nprint(\"opposite words\", opposite_words)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:20:21.897103Z","iopub.execute_input":"2025-04-19T17:20:21.897399Z","iopub.status.idle":"2025-04-19T17:20:44.757918Z","shell.execute_reply.started":"2025-04-19T17:20:21.897371Z","shell.execute_reply":"2025-04-19T17:20:44.756852Z"}},"outputs":[{"name":"stdout","text":"Loading the model...\n<fasttext.FastText._FastText object at 0x7c722f235f90>\nVocabulary Size: 2000000\nEmbedding Size: 300\nsimilar words [(0.7517593502998352, 'bad'), (0.7426098585128784, 'great'), (0.7299689054489136, 'decent'), (0.7123614549636841, 'nice'), (0.6796907186508179, 'Good'), (0.6737031936645508, 'excellent'), (0.669592022895813, 'goood'), (0.6602178812026978, 'ggod'), (0.6479219794273376, 'semi-good'), (0.6417751908302307, 'good.Good')]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/297213840.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msimilar_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_nearest_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"good\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"similar words\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msimilar_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mopposite_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_nearest_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"learning\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"opposite words\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopposite_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: _FastText.get_nearest_neighbors() got an unexpected keyword argument 'negative'"],"ename":"TypeError","evalue":"_FastText.get_nearest_neighbors() got an unexpected keyword argument 'negative'","output_type":"error"}],"execution_count":12},{"cell_type":"markdown","source":"- import fasttext\n    - Facebook's original FastText package.\n    - Faster and more memory efficient\n    - Limited API (e.g., doesn't support negative sampling like Gensim does).\n    - get_nearest_neighbors(negative) doesnâ€™t exist in official fasttext\n    - Used in real Prijects (Production)","metadata":{}},{"cell_type":"markdown","source":"- Gensim FastText\n    - You can use: (positive, negative, most_similar, similarity, .....)\n    - Slightly slower\n    - For production embedding lookup, not as efficient as the original FastText.","metadata":{}},{"cell_type":"code","source":"from gensim.models.fasttext import load_facebook_model\n\npretrained = load_facebook_model(\"cc.en.300.bin\")\n# model = load_facebook_model(output_bin)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:22:21.519417Z","iopub.execute_input":"2025-04-19T17:22:21.519877Z","iopub.status.idle":"2025-04-19T17:24:27.142626Z","shell.execute_reply.started":"2025-04-19T17:22:21.519849Z","shell.execute_reply":"2025-04-19T17:24:27.141885Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"vocab_size = len(pretrained.wv)\nembedding_size = pretrained.wv.vector_size\nprint(f\"Vocabulary Size: {vocab_size}\")\nprint(f\"Embedding Size: {embedding_size}\")\nsimilar = pretrained.wv.most_similar(\"learning\", topn=10)\nprint(\"similar words :\", similar)\n\nopposite_words = pretrained.wv.most_similar(negative=[\"learning\"],topn=10)\nprint(\"\\n\\nopposite words :\", opposite_words)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:24:27.146361Z","iopub.execute_input":"2025-04-19T17:24:27.146631Z","iopub.status.idle":"2025-04-19T17:24:28.242978Z","shell.execute_reply.started":"2025-04-19T17:24:27.146609Z","shell.execute_reply":"2025-04-19T17:24:28.242127Z"}},"outputs":[{"name":"stdout","text":"Vocabulary Size: 2000000\nEmbedding Size: 300\nsimilar words : [('learing', 0.7456762194633484), ('Learning', 0.6895480751991272), ('learning.This', 0.687819242477417), ('learning.The', 0.6796228289604187), ('learning.It', 0.6753032207489014), ('learning.So', 0.6706693768501282), ('learning.What', 0.6673311591148376), ('learning.But', 0.6648256778717041), ('learning-', 0.6643092036247253), ('learning.As', 0.6633589267730713)]\n\n\nopposite words : [('19555', 0.2533474564552307), ('12291', 0.23999808728694916), ('10264', 0.2394980639219284), ('13107', 0.23354505002498627), ('8504', 0.23330195248126984), ('13223', 0.23251304030418396), ('7242', 0.23047803342342377), ('13466', 0.2299567013978958), ('10494', 0.22803275287151337), ('14138', 0.2278987020254135)]\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"pretrained.build_vocab(sentences, update=True)\npretrained.train(\n    sentences,\n    total_examples=len(sentences),\n    epochs=10\n)\n# Print vocabulary and embedding size\nvocab_size = len(pretrained.wv)\nembedding_size = pretrained.vector_size\nprint(f\"Vocabulary Size: {vocab_size}\")\nprint(f\"Embedding Size: {embedding_size}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:24:28.244081Z","iopub.execute_input":"2025-04-19T17:24:28.244314Z","iopub.status.idle":"2025-04-19T17:26:12.710272Z","shell.execute_reply.started":"2025-04-19T17:24:28.244297Z","shell.execute_reply":"2025-04-19T17:26:12.709490Z"}},"outputs":[{"name":"stdout","text":"Vocabulary Size: 2000000\nEmbedding Size: 300\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"similar_words = pretrained.wv.most_similar(\"learn\", topn=10)\nopposite_words = pretrained.wv.most_similar(negative=\"learn\", topn=10)\nprint(similar_words, \"\\n\\n\", opposite_words)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:26:12.711506Z","iopub.execute_input":"2025-04-19T17:26:12.711753Z","iopub.status.idle":"2025-04-19T17:26:13.760293Z","shell.execute_reply.started":"2025-04-19T17:26:12.711729Z","shell.execute_reply":"2025-04-19T17:26:13.759226Z"}},"outputs":[{"name":"stdout","text":"[('teach', 0.716772198677063), ('Learn', 0.7041028738021851), ('learned', 0.6968039274215698), ('learm', 0.6521831750869751), ('re-learn', 0.6518067717552185), ('discover', 0.6409897208213806), ('learn.If', 0.6341798901557922), ('relearn', 0.6159347295761108), ('leanr', 0.6142886877059937), ('understand', 0.6114104390144348)] \n\n [('.Rear', 0.22274798154830933), ('3.825', 0.20031915605068207), ('1.638', 0.19616979360580444), ('W52', 0.19612562656402588), ('3.725', 0.19571073353290558), ('9,677', 0.1925133764743805), ('2.101', 0.19243070483207703), ('2.675', 0.1889045089483261), ('3.425', 0.1883799433708191), ('2.76m', 0.1873113363981247)]\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}